{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "sys.path.insert(0, './common')\n",
    "\n",
    "import sys\n",
    "import wave_gym_env"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WAVE environment created.\n"
     ]
    }
   ],
   "source": [
    "env_path = 'collectible/Wave'\n",
    "env = wave_gym_env.CustomEnv(env_path, worker_id=10, timescale=30)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\nathan\\AppData\\Local\\Programs\\Python\\Python310\\lib\\site-packages\\tqdm\\auto.py:22: TqdmWarning: IProgress not found. Please update jupyter and ipywidgets. See https://ipywidgets.readthedocs.io/en/stable/user_install.html\n",
      "  from .autonotebook import tqdm as notebook_tqdm\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Using cpu device\n",
      "Wrapping the env with a `Monitor` wrapper\n",
      "Wrapping the env in a DummyVecEnv.\n",
      "Logging to ./openai_log/a2c/A2C_1\n",
      "------------------------------------\n",
      "| rollout/              |          |\n",
      "|    ep_len_mean        | 69.5     |\n",
      "|    ep_rew_mean        | 0.747    |\n",
      "| time/                 |          |\n",
      "|    fps                | 293      |\n",
      "|    iterations         | 100      |\n",
      "|    time_elapsed       | 341      |\n",
      "|    total_timesteps    | 100000   |\n",
      "| train/                |          |\n",
      "|    entropy_loss       | -0.595   |\n",
      "|    explained_variance | 0.0516   |\n",
      "|    learning_rate      | 0.0007   |\n",
      "|    n_updates          | 99       |\n",
      "|    policy_loss        | 0.866    |\n",
      "|    value_loss         | 43       |\n",
      "------------------------------------\n",
      "------------------------------------\n",
      "| rollout/              |          |\n",
      "|    ep_len_mean        | 111      |\n",
      "|    ep_rew_mean        | 7.95     |\n",
      "| time/                 |          |\n",
      "|    fps                | 295      |\n",
      "|    iterations         | 200      |\n",
      "|    time_elapsed       | 677      |\n",
      "|    total_timesteps    | 200000   |\n",
      "| train/                |          |\n",
      "|    entropy_loss       | -0.474   |\n",
      "|    explained_variance | 0.0728   |\n",
      "|    learning_rate      | 0.0007   |\n",
      "|    n_updates          | 199      |\n",
      "|    policy_loss        | 1.09     |\n",
      "|    value_loss         | 61.5     |\n",
      "------------------------------------\n",
      "------------------------------------\n",
      "| rollout/              |          |\n",
      "|    ep_len_mean        | 205      |\n",
      "|    ep_rew_mean        | 25.1     |\n",
      "| time/                 |          |\n",
      "|    fps                | 296      |\n",
      "|    iterations         | 300      |\n",
      "|    time_elapsed       | 1012     |\n",
      "|    total_timesteps    | 300000   |\n",
      "| train/                |          |\n",
      "|    entropy_loss       | -0.415   |\n",
      "|    explained_variance | 0.141    |\n",
      "|    learning_rate      | 0.0007   |\n",
      "|    n_updates          | 299      |\n",
      "|    policy_loss        | -0.0491  |\n",
      "|    value_loss         | 47.1     |\n",
      "------------------------------------\n",
      "------------------------------------\n",
      "| rollout/              |          |\n",
      "|    ep_len_mean        | 258      |\n",
      "|    ep_rew_mean        | 38.3     |\n",
      "| time/                 |          |\n",
      "|    fps                | 297      |\n",
      "|    iterations         | 400      |\n",
      "|    time_elapsed       | 1346     |\n",
      "|    total_timesteps    | 400000   |\n",
      "| train/                |          |\n",
      "|    entropy_loss       | -0.362   |\n",
      "|    explained_variance | 0.0973   |\n",
      "|    learning_rate      | 0.0007   |\n",
      "|    n_updates          | 399      |\n",
      "|    policy_loss        | -0.702   |\n",
      "|    value_loss         | 72.1     |\n",
      "------------------------------------\n",
      "------------------------------------\n",
      "| rollout/              |          |\n",
      "|    ep_len_mean        | 265      |\n",
      "|    ep_rew_mean        | 35.3     |\n",
      "| time/                 |          |\n",
      "|    fps                | 297      |\n",
      "|    iterations         | 500      |\n",
      "|    time_elapsed       | 1681     |\n",
      "|    total_timesteps    | 500000   |\n",
      "| train/                |          |\n",
      "|    entropy_loss       | -0.332   |\n",
      "|    explained_variance | 0.0921   |\n",
      "|    learning_rate      | 0.0007   |\n",
      "|    n_updates          | 499      |\n",
      "|    policy_loss        | 1.81     |\n",
      "|    value_loss         | 81.2     |\n",
      "------------------------------------\n",
      "------------------------------------\n",
      "| rollout/              |          |\n",
      "|    ep_len_mean        | 296      |\n",
      "|    ep_rew_mean        | 41.9     |\n",
      "| time/                 |          |\n",
      "|    fps                | 297      |\n",
      "|    iterations         | 600      |\n",
      "|    time_elapsed       | 2015     |\n",
      "|    total_timesteps    | 600000   |\n",
      "| train/                |          |\n",
      "|    entropy_loss       | -0.286   |\n",
      "|    explained_variance | 0.111    |\n",
      "|    learning_rate      | 0.0007   |\n",
      "|    n_updates          | 599      |\n",
      "|    policy_loss        | 0.699    |\n",
      "|    value_loss         | 66.5     |\n",
      "------------------------------------\n",
      "------------------------------------\n",
      "| rollout/              |          |\n",
      "|    ep_len_mean        | 468      |\n",
      "|    ep_rew_mean        | 76.3     |\n",
      "| time/                 |          |\n",
      "|    fps                | 297      |\n",
      "|    iterations         | 700      |\n",
      "|    time_elapsed       | 2349     |\n",
      "|    total_timesteps    | 700000   |\n",
      "| train/                |          |\n",
      "|    entropy_loss       | -0.263   |\n",
      "|    explained_variance | 0.134    |\n",
      "|    learning_rate      | 0.0007   |\n",
      "|    n_updates          | 699      |\n",
      "|    policy_loss        | -0.439   |\n",
      "|    value_loss         | 57       |\n",
      "------------------------------------\n",
      "------------------------------------\n",
      "| rollout/              |          |\n",
      "|    ep_len_mean        | 286      |\n",
      "|    ep_rew_mean        | 39.8     |\n",
      "| time/                 |          |\n",
      "|    fps                | 298      |\n",
      "|    iterations         | 800      |\n",
      "|    time_elapsed       | 2683     |\n",
      "|    total_timesteps    | 800000   |\n",
      "| train/                |          |\n",
      "|    entropy_loss       | -0.275   |\n",
      "|    explained_variance | 0.249    |\n",
      "|    learning_rate      | 0.0007   |\n",
      "|    n_updates          | 799      |\n",
      "|    policy_loss        | 1.36     |\n",
      "|    value_loss         | 92.9     |\n",
      "------------------------------------\n",
      "------------------------------------\n",
      "| rollout/              |          |\n",
      "|    ep_len_mean        | 381      |\n",
      "|    ep_rew_mean        | 60.4     |\n",
      "| time/                 |          |\n",
      "|    fps                | 298      |\n",
      "|    iterations         | 900      |\n",
      "|    time_elapsed       | 3017     |\n",
      "|    total_timesteps    | 900000   |\n",
      "| train/                |          |\n",
      "|    entropy_loss       | -0.218   |\n",
      "|    explained_variance | 0.191    |\n",
      "|    learning_rate      | 0.0007   |\n",
      "|    n_updates          | 899      |\n",
      "|    policy_loss        | 0.863    |\n",
      "|    value_loss         | 103      |\n",
      "------------------------------------\n",
      "------------------------------------\n",
      "| rollout/              |          |\n",
      "|    ep_len_mean        | 480      |\n",
      "|    ep_rew_mean        | 89.5     |\n",
      "| time/                 |          |\n",
      "|    fps                | 298      |\n",
      "|    iterations         | 1000     |\n",
      "|    time_elapsed       | 3351     |\n",
      "|    total_timesteps    | 1000000  |\n",
      "| train/                |          |\n",
      "|    entropy_loss       | -0.197   |\n",
      "|    explained_variance | 0.0649   |\n",
      "|    learning_rate      | 0.0007   |\n",
      "|    n_updates          | 999      |\n",
      "|    policy_loss        | -0.132   |\n",
      "|    value_loss         | 45.9     |\n",
      "------------------------------------\n",
      "------------------------------------\n",
      "| rollout/              |          |\n",
      "|    ep_len_mean        | 155      |\n",
      "|    ep_rew_mean        | 18.2     |\n",
      "| time/                 |          |\n",
      "|    fps                | 298      |\n",
      "|    iterations         | 1100     |\n",
      "|    time_elapsed       | 3685     |\n",
      "|    total_timesteps    | 1100000  |\n",
      "| train/                |          |\n",
      "|    entropy_loss       | -0.202   |\n",
      "|    explained_variance | 0.129    |\n",
      "|    learning_rate      | 0.0007   |\n",
      "|    n_updates          | 1099     |\n",
      "|    policy_loss        | -1.22    |\n",
      "|    value_loss         | 93.6     |\n",
      "------------------------------------\n",
      "------------------------------------\n",
      "| rollout/              |          |\n",
      "|    ep_len_mean        | 362      |\n",
      "|    ep_rew_mean        | 60.6     |\n",
      "| time/                 |          |\n",
      "|    fps                | 298      |\n",
      "|    iterations         | 1200     |\n",
      "|    time_elapsed       | 4020     |\n",
      "|    total_timesteps    | 1200000  |\n",
      "| train/                |          |\n",
      "|    entropy_loss       | -0.182   |\n",
      "|    explained_variance | 0.0465   |\n",
      "|    learning_rate      | 0.0007   |\n",
      "|    n_updates          | 1199     |\n",
      "|    policy_loss        | 1.15     |\n",
      "|    value_loss         | 63.9     |\n",
      "------------------------------------\n",
      "------------------------------------\n",
      "| rollout/              |          |\n",
      "|    ep_len_mean        | 601      |\n",
      "|    ep_rew_mean        | 108      |\n",
      "| time/                 |          |\n",
      "|    fps                | 298      |\n",
      "|    iterations         | 1300     |\n",
      "|    time_elapsed       | 4353     |\n",
      "|    total_timesteps    | 1300000  |\n",
      "| train/                |          |\n",
      "|    entropy_loss       | -0.164   |\n",
      "|    explained_variance | 0.0872   |\n",
      "|    learning_rate      | 0.0007   |\n",
      "|    n_updates          | 1299     |\n",
      "|    policy_loss        | -0.959   |\n",
      "|    value_loss         | 93.4     |\n",
      "------------------------------------\n",
      "------------------------------------\n",
      "| rollout/              |          |\n",
      "|    ep_len_mean        | 463      |\n",
      "|    ep_rew_mean        | 78.9     |\n",
      "| time/                 |          |\n",
      "|    fps                | 298      |\n",
      "|    iterations         | 1400     |\n",
      "|    time_elapsed       | 4688     |\n",
      "|    total_timesteps    | 1400000  |\n",
      "| train/                |          |\n",
      "|    entropy_loss       | -0.144   |\n",
      "|    explained_variance | 0.137    |\n",
      "|    learning_rate      | 0.0007   |\n",
      "|    n_updates          | 1399     |\n",
      "|    policy_loss        | -1.09    |\n",
      "|    value_loss         | 131      |\n",
      "------------------------------------\n",
      "------------------------------------\n",
      "| rollout/              |          |\n",
      "|    ep_len_mean        | 603      |\n",
      "|    ep_rew_mean        | 109      |\n",
      "| time/                 |          |\n",
      "|    fps                | 298      |\n",
      "|    iterations         | 1500     |\n",
      "|    time_elapsed       | 5022     |\n",
      "|    total_timesteps    | 1500000  |\n",
      "| train/                |          |\n",
      "|    entropy_loss       | -0.152   |\n",
      "|    explained_variance | 0.282    |\n",
      "|    learning_rate      | 0.0007   |\n",
      "|    n_updates          | 1499     |\n",
      "|    policy_loss        | -0.0846  |\n",
      "|    value_loss         | 44.4     |\n",
      "------------------------------------\n",
      "------------------------------------\n",
      "| rollout/              |          |\n",
      "|    ep_len_mean        | 194      |\n",
      "|    ep_rew_mean        | 21.3     |\n",
      "| time/                 |          |\n",
      "|    fps                | 298      |\n",
      "|    iterations         | 1600     |\n",
      "|    time_elapsed       | 5357     |\n",
      "|    total_timesteps    | 1600000  |\n",
      "| train/                |          |\n",
      "|    entropy_loss       | -0.143   |\n",
      "|    explained_variance | 0.183    |\n",
      "|    learning_rate      | 0.0007   |\n",
      "|    n_updates          | 1599     |\n",
      "|    policy_loss        | 0.06     |\n",
      "|    value_loss         | 68.4     |\n",
      "------------------------------------\n",
      "------------------------------------\n",
      "| rollout/              |          |\n",
      "|    ep_len_mean        | 284      |\n",
      "|    ep_rew_mean        | 40.5     |\n",
      "| time/                 |          |\n",
      "|    fps                | 298      |\n",
      "|    iterations         | 1700     |\n",
      "|    time_elapsed       | 5691     |\n",
      "|    total_timesteps    | 1700000  |\n",
      "| train/                |          |\n",
      "|    entropy_loss       | -0.148   |\n",
      "|    explained_variance | 0.28     |\n",
      "|    learning_rate      | 0.0007   |\n",
      "|    n_updates          | 1699     |\n",
      "|    policy_loss        | 0.544    |\n",
      "|    value_loss         | 38.1     |\n",
      "------------------------------------\n",
      "------------------------------------\n",
      "| rollout/              |          |\n",
      "|    ep_len_mean        | 579      |\n",
      "|    ep_rew_mean        | 105      |\n",
      "| time/                 |          |\n",
      "|    fps                | 298      |\n",
      "|    iterations         | 1800     |\n",
      "|    time_elapsed       | 6025     |\n",
      "|    total_timesteps    | 1800000  |\n",
      "| train/                |          |\n",
      "|    entropy_loss       | -0.129   |\n",
      "|    explained_variance | 0.261    |\n",
      "|    learning_rate      | 0.0007   |\n",
      "|    n_updates          | 1799     |\n",
      "|    policy_loss        | 0.278    |\n",
      "|    value_loss         | 47.6     |\n",
      "------------------------------------\n",
      "------------------------------------\n",
      "| rollout/              |          |\n",
      "|    ep_len_mean        | 574      |\n",
      "|    ep_rew_mean        | 108      |\n",
      "| time/                 |          |\n",
      "|    fps                | 298      |\n",
      "|    iterations         | 1900     |\n",
      "|    time_elapsed       | 6359     |\n",
      "|    total_timesteps    | 1900000  |\n",
      "| train/                |          |\n",
      "|    entropy_loss       | -0.129   |\n",
      "|    explained_variance | 0.0937   |\n",
      "|    learning_rate      | 0.0007   |\n",
      "|    n_updates          | 1899     |\n",
      "|    policy_loss        | 0.699    |\n",
      "|    value_loss         | 37.4     |\n",
      "------------------------------------\n",
      "------------------------------------\n",
      "| rollout/              |          |\n",
      "|    ep_len_mean        | 796      |\n",
      "|    ep_rew_mean        | 156      |\n",
      "| time/                 |          |\n",
      "|    fps                | 298      |\n",
      "|    iterations         | 2000     |\n",
      "|    time_elapsed       | 6692     |\n",
      "|    total_timesteps    | 2000000  |\n",
      "| train/                |          |\n",
      "|    entropy_loss       | -0.135   |\n",
      "|    explained_variance | 0.0121   |\n",
      "|    learning_rate      | 0.0007   |\n",
      "|    n_updates          | 1999     |\n",
      "|    policy_loss        | -0.348   |\n",
      "|    value_loss         | 52.4     |\n",
      "------------------------------------\n",
      "------------------------------------\n",
      "| rollout/              |          |\n",
      "|    ep_len_mean        | 491      |\n",
      "|    ep_rew_mean        | 88       |\n",
      "| time/                 |          |\n",
      "|    fps                | 298      |\n",
      "|    iterations         | 2100     |\n",
      "|    time_elapsed       | 7026     |\n",
      "|    total_timesteps    | 2100000  |\n",
      "| train/                |          |\n",
      "|    entropy_loss       | -0.106   |\n",
      "|    explained_variance | 0.178    |\n",
      "|    learning_rate      | 0.0007   |\n",
      "|    n_updates          | 2099     |\n",
      "|    policy_loss        | 0.00362  |\n",
      "|    value_loss         | 54.8     |\n",
      "------------------------------------\n",
      "------------------------------------\n",
      "| rollout/              |          |\n",
      "|    ep_len_mean        | 657      |\n",
      "|    ep_rew_mean        | 124      |\n",
      "| time/                 |          |\n",
      "|    fps                | 298      |\n",
      "|    iterations         | 2200     |\n",
      "|    time_elapsed       | 7360     |\n",
      "|    total_timesteps    | 2200000  |\n",
      "| train/                |          |\n",
      "|    entropy_loss       | -0.122   |\n",
      "|    explained_variance | 0.129    |\n",
      "|    learning_rate      | 0.0007   |\n",
      "|    n_updates          | 2199     |\n",
      "|    policy_loss        | -1.18    |\n",
      "|    value_loss         | 141      |\n",
      "------------------------------------\n",
      "------------------------------------\n",
      "| rollout/              |          |\n",
      "|    ep_len_mean        | 475      |\n",
      "|    ep_rew_mean        | 81.5     |\n",
      "| time/                 |          |\n",
      "|    fps                | 298      |\n",
      "|    iterations         | 2300     |\n",
      "|    time_elapsed       | 7694     |\n",
      "|    total_timesteps    | 2300000  |\n",
      "| train/                |          |\n",
      "|    entropy_loss       | -0.101   |\n",
      "|    explained_variance | 0.0284   |\n",
      "|    learning_rate      | 0.0007   |\n",
      "|    n_updates          | 2299     |\n",
      "|    policy_loss        | -0.581   |\n",
      "|    value_loss         | 76.2     |\n",
      "------------------------------------\n",
      "------------------------------------\n",
      "| rollout/              |          |\n",
      "|    ep_len_mean        | 635      |\n",
      "|    ep_rew_mean        | 121      |\n",
      "| time/                 |          |\n",
      "|    fps                | 298      |\n",
      "|    iterations         | 2400     |\n",
      "|    time_elapsed       | 8028     |\n",
      "|    total_timesteps    | 2400000  |\n",
      "| train/                |          |\n",
      "|    entropy_loss       | -0.0996  |\n",
      "|    explained_variance | 0.0996   |\n",
      "|    learning_rate      | 0.0007   |\n",
      "|    n_updates          | 2399     |\n",
      "|    policy_loss        | -0.47    |\n",
      "|    value_loss         | 101      |\n",
      "------------------------------------\n",
      "------------------------------------\n",
      "| rollout/              |          |\n",
      "|    ep_len_mean        | 501      |\n",
      "|    ep_rew_mean        | 89.6     |\n",
      "| time/                 |          |\n",
      "|    fps                | 298      |\n",
      "|    iterations         | 2500     |\n",
      "|    time_elapsed       | 8362     |\n",
      "|    total_timesteps    | 2500000  |\n",
      "| train/                |          |\n",
      "|    entropy_loss       | -0.0862  |\n",
      "|    explained_variance | 0.172    |\n",
      "|    learning_rate      | 0.0007   |\n",
      "|    n_updates          | 2499     |\n",
      "|    policy_loss        | 0.0669   |\n",
      "|    value_loss         | 18.6     |\n",
      "------------------------------------\n",
      "------------------------------------\n",
      "| rollout/              |          |\n",
      "|    ep_len_mean        | 709      |\n",
      "|    ep_rew_mean        | 135      |\n",
      "| time/                 |          |\n",
      "|    fps                | 298      |\n",
      "|    iterations         | 2600     |\n",
      "|    time_elapsed       | 8696     |\n",
      "|    total_timesteps    | 2600000  |\n",
      "| train/                |          |\n",
      "|    entropy_loss       | -0.105   |\n",
      "|    explained_variance | 0.249    |\n",
      "|    learning_rate      | 0.0007   |\n",
      "|    n_updates          | 2599     |\n",
      "|    policy_loss        | -0.0648  |\n",
      "|    value_loss         | 13.7     |\n",
      "------------------------------------\n",
      "------------------------------------\n",
      "| rollout/              |          |\n",
      "|    ep_len_mean        | 741      |\n",
      "|    ep_rew_mean        | 144      |\n",
      "| time/                 |          |\n",
      "|    fps                | 299      |\n",
      "|    iterations         | 2700     |\n",
      "|    time_elapsed       | 9029     |\n",
      "|    total_timesteps    | 2700000  |\n",
      "| train/                |          |\n",
      "|    entropy_loss       | -0.0908  |\n",
      "|    explained_variance | 0.0434   |\n",
      "|    learning_rate      | 0.0007   |\n",
      "|    n_updates          | 2699     |\n",
      "|    policy_loss        | 0.375    |\n",
      "|    value_loss         | 29.5     |\n",
      "------------------------------------\n",
      "------------------------------------\n",
      "| rollout/              |          |\n",
      "|    ep_len_mean        | 511      |\n",
      "|    ep_rew_mean        | 95.7     |\n",
      "| time/                 |          |\n",
      "|    fps                | 299      |\n",
      "|    iterations         | 2800     |\n",
      "|    time_elapsed       | 9364     |\n",
      "|    total_timesteps    | 2800000  |\n",
      "| train/                |          |\n",
      "|    entropy_loss       | -0.103   |\n",
      "|    explained_variance | 0.225    |\n",
      "|    learning_rate      | 0.0007   |\n",
      "|    n_updates          | 2799     |\n",
      "|    policy_loss        | -0.0383  |\n",
      "|    value_loss         | 53.4     |\n",
      "------------------------------------\n",
      "------------------------------------\n",
      "| rollout/              |          |\n",
      "|    ep_len_mean        | 636      |\n",
      "|    ep_rew_mean        | 119      |\n",
      "| time/                 |          |\n",
      "|    fps                | 299      |\n",
      "|    iterations         | 2900     |\n",
      "|    time_elapsed       | 9698     |\n",
      "|    total_timesteps    | 2900000  |\n",
      "| train/                |          |\n",
      "|    entropy_loss       | -0.108   |\n",
      "|    explained_variance | 0.139    |\n",
      "|    learning_rate      | 0.0007   |\n",
      "|    n_updates          | 2899     |\n",
      "|    policy_loss        | -0.405   |\n",
      "|    value_loss         | 64.5     |\n",
      "------------------------------------\n",
      "------------------------------------\n",
      "| rollout/              |          |\n",
      "|    ep_len_mean        | 665      |\n",
      "|    ep_rew_mean        | 128      |\n",
      "| time/                 |          |\n",
      "|    fps                | 299      |\n",
      "|    iterations         | 3000     |\n",
      "|    time_elapsed       | 10031    |\n",
      "|    total_timesteps    | 3000000  |\n",
      "| train/                |          |\n",
      "|    entropy_loss       | -0.1     |\n",
      "|    explained_variance | 0.226    |\n",
      "|    learning_rate      | 0.0007   |\n",
      "|    n_updates          | 2999     |\n",
      "|    policy_loss        | -0.097   |\n",
      "|    value_loss         | 64.8     |\n",
      "------------------------------------\n",
      "------------------------------------\n",
      "| rollout/              |          |\n",
      "|    ep_len_mean        | 119      |\n",
      "|    ep_rew_mean        | 9.53     |\n",
      "| time/                 |          |\n",
      "|    fps                | 299      |\n",
      "|    iterations         | 3100     |\n",
      "|    time_elapsed       | 10366    |\n",
      "|    total_timesteps    | 3100000  |\n",
      "| train/                |          |\n",
      "|    entropy_loss       | -0.0977  |\n",
      "|    explained_variance | 0.112    |\n",
      "|    learning_rate      | 0.0007   |\n",
      "|    n_updates          | 3099     |\n",
      "|    policy_loss        | 0.372    |\n",
      "|    value_loss         | 89       |\n",
      "------------------------------------\n",
      "------------------------------------\n",
      "| rollout/              |          |\n",
      "|    ep_len_mean        | 571      |\n",
      "|    ep_rew_mean        | 113      |\n",
      "| time/                 |          |\n",
      "|    fps                | 299      |\n",
      "|    iterations         | 3200     |\n",
      "|    time_elapsed       | 10700    |\n",
      "|    total_timesteps    | 3200000  |\n",
      "| train/                |          |\n",
      "|    entropy_loss       | -0.089   |\n",
      "|    explained_variance | 0.0445   |\n",
      "|    learning_rate      | 0.0007   |\n",
      "|    n_updates          | 3199     |\n",
      "|    policy_loss        | -0.172   |\n",
      "|    value_loss         | 68.4     |\n",
      "------------------------------------\n",
      "------------------------------------\n",
      "| rollout/              |          |\n",
      "|    ep_len_mean        | 393      |\n",
      "|    ep_rew_mean        | 75.7     |\n",
      "| time/                 |          |\n",
      "|    fps                | 299      |\n",
      "|    iterations         | 3300     |\n",
      "|    time_elapsed       | 11034    |\n",
      "|    total_timesteps    | 3300000  |\n",
      "| train/                |          |\n",
      "|    entropy_loss       | -0.103   |\n",
      "|    explained_variance | 0.132    |\n",
      "|    learning_rate      | 0.0007   |\n",
      "|    n_updates          | 3299     |\n",
      "|    policy_loss        | -0.678   |\n",
      "|    value_loss         | 78.4     |\n",
      "------------------------------------\n",
      "------------------------------------\n",
      "| rollout/              |          |\n",
      "|    ep_len_mean        | 145      |\n",
      "|    ep_rew_mean        | 18.5     |\n",
      "| time/                 |          |\n",
      "|    fps                | 299      |\n",
      "|    iterations         | 3400     |\n",
      "|    time_elapsed       | 11368    |\n",
      "|    total_timesteps    | 3400000  |\n",
      "| train/                |          |\n",
      "|    entropy_loss       | -0.0704  |\n",
      "|    explained_variance | 0.148    |\n",
      "|    learning_rate      | 0.0007   |\n",
      "|    n_updates          | 3399     |\n",
      "|    policy_loss        | -0.242   |\n",
      "|    value_loss         | 66       |\n",
      "------------------------------------\n",
      "------------------------------------\n",
      "| rollout/              |          |\n",
      "|    ep_len_mean        | 298      |\n",
      "|    ep_rew_mean        | 49.6     |\n",
      "| time/                 |          |\n",
      "|    fps                | 299      |\n",
      "|    iterations         | 3500     |\n",
      "|    time_elapsed       | 11704    |\n",
      "|    total_timesteps    | 3500000  |\n",
      "| train/                |          |\n",
      "|    entropy_loss       | -0.109   |\n",
      "|    explained_variance | 0.122    |\n",
      "|    learning_rate      | 0.0007   |\n",
      "|    n_updates          | 3499     |\n",
      "|    policy_loss        | -0.572   |\n",
      "|    value_loss         | 86       |\n",
      "------------------------------------\n",
      "------------------------------------\n",
      "| rollout/              |          |\n",
      "|    ep_len_mean        | 507      |\n",
      "|    ep_rew_mean        | 95.8     |\n",
      "| time/                 |          |\n",
      "|    fps                | 299      |\n",
      "|    iterations         | 3600     |\n",
      "|    time_elapsed       | 12039    |\n",
      "|    total_timesteps    | 3600000  |\n",
      "| train/                |          |\n",
      "|    entropy_loss       | -0.0899  |\n",
      "|    explained_variance | 0.0824   |\n",
      "|    learning_rate      | 0.0007   |\n",
      "|    n_updates          | 3599     |\n",
      "|    policy_loss        | -0.548   |\n",
      "|    value_loss         | 81.1     |\n",
      "------------------------------------\n"
     ]
    }
   ],
   "source": [
    "from stable_baselines3 import A2C\n",
    "\n",
    "model = A2C(\"MlpPolicy\", env, verbose=1, gamma=0.99, tensorboard_log=\"./openai_log/a2c/\", n_steps=1000, ent_coef=0.01)\n",
    "model.learn(total_timesteps=5000000)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "model.save(\"ppo_wave\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'PPO' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[1;32mf:\\Nathan\\!SKRIPSI\\rl-wave\\openai_ppo.ipynb Cell 5'\u001b[0m in \u001b[0;36m<cell line: 1>\u001b[1;34m()\u001b[0m\n\u001b[1;32m----> <a href='vscode-notebook-cell:/f%3A/Nathan/%21SKRIPSI/rl-wave/openai_ppo.ipynb#ch0000007?line=0'>1</a>\u001b[0m model \u001b[39m=\u001b[39m PPO\u001b[39m.\u001b[39mload(\u001b[39m\"\u001b[39m\u001b[39mppo_wave\u001b[39m\u001b[39m\"\u001b[39m)\n",
      "\u001b[1;31mNameError\u001b[0m: name 'PPO' is not defined"
     ]
    }
   ],
   "source": [
    "model = PPO.load(\"ppo_wave\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "env.close()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WAVE environment created.\n"
     ]
    },
    {
     "ename": "UnityCommunicatorStoppedException",
     "evalue": "Communicator has exited.",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mUnityCommunicatorStoppedException\u001b[0m         Traceback (most recent call last)",
      "\u001b[1;32mf:\\Nathan\\!SKRIPSI\\rl-wave\\openai_ppo.ipynb Cell 7'\u001b[0m in \u001b[0;36m<cell line: 5>\u001b[1;34m()\u001b[0m\n\u001b[0;32m      <a href='vscode-notebook-cell:/f%3A/Nathan/%21SKRIPSI/rl-wave/openai_ppo.ipynb#ch0000006?line=4'>5</a>\u001b[0m \u001b[39mwhile\u001b[39;00m \u001b[39mnot\u001b[39;00m dones:\n\u001b[0;32m      <a href='vscode-notebook-cell:/f%3A/Nathan/%21SKRIPSI/rl-wave/openai_ppo.ipynb#ch0000006?line=5'>6</a>\u001b[0m     action, _states \u001b[39m=\u001b[39m model\u001b[39m.\u001b[39mpredict(obs)\n\u001b[1;32m----> <a href='vscode-notebook-cell:/f%3A/Nathan/%21SKRIPSI/rl-wave/openai_ppo.ipynb#ch0000006?line=6'>7</a>\u001b[0m     obs, rewards, dones, info \u001b[39m=\u001b[39m env\u001b[39m.\u001b[39;49mstep(action)\n\u001b[0;32m      <a href='vscode-notebook-cell:/f%3A/Nathan/%21SKRIPSI/rl-wave/openai_ppo.ipynb#ch0000006?line=8'>9</a>\u001b[0m env\u001b[39m.\u001b[39mclose()\n",
      "File \u001b[1;32mf:\\Nathan\\!SKRIPSI\\rl-wave\\./common\\wave_gym_env.py:53\u001b[0m, in \u001b[0;36mCustomEnv.step\u001b[1;34m(self, action)\u001b[0m\n\u001b[0;32m     <a href='file:///f%3A/Nathan/%21SKRIPSI/rl-wave/./common/wave_gym_env.py?line=50'>51</a>\u001b[0m action_tuple\u001b[39m.\u001b[39madd_discrete(np\u001b[39m.\u001b[39marray([[action]]))\n\u001b[0;32m     <a href='file:///f%3A/Nathan/%21SKRIPSI/rl-wave/./common/wave_gym_env.py?line=51'>52</a>\u001b[0m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39menv\u001b[39m.\u001b[39mset_actions(\u001b[39mself\u001b[39m\u001b[39m.\u001b[39mget_behavior_name(), action_tuple)\n\u001b[1;32m---> <a href='file:///f%3A/Nathan/%21SKRIPSI/rl-wave/./common/wave_gym_env.py?line=52'>53</a>\u001b[0m \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49menv\u001b[39m.\u001b[39;49mstep()\n\u001b[0;32m     <a href='file:///f%3A/Nathan/%21SKRIPSI/rl-wave/./common/wave_gym_env.py?line=54'>55</a>\u001b[0m state, reward, is_done \u001b[39m=\u001b[39m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mget_current_state()\n\u001b[0;32m     <a href='file:///f%3A/Nathan/%21SKRIPSI/rl-wave/./common/wave_gym_env.py?line=56'>57</a>\u001b[0m \u001b[39mreturn\u001b[39;00m state, reward, is_done, {}\n",
      "File \u001b[1;32mc:\\Users\\nathan\\AppData\\Local\\Programs\\Python\\Python310\\lib\\site-packages\\mlagents_envs\\timers.py:305\u001b[0m, in \u001b[0;36mtimed.<locals>.wrapped\u001b[1;34m(*args, **kwargs)\u001b[0m\n\u001b[0;32m    <a href='file:///c%3A/Users/nathan/AppData/Local/Programs/Python/Python310/lib/site-packages/mlagents_envs/timers.py?line=302'>303</a>\u001b[0m \u001b[39mdef\u001b[39;00m \u001b[39mwrapped\u001b[39m(\u001b[39m*\u001b[39margs, \u001b[39m*\u001b[39m\u001b[39m*\u001b[39mkwargs):\n\u001b[0;32m    <a href='file:///c%3A/Users/nathan/AppData/Local/Programs/Python/Python310/lib/site-packages/mlagents_envs/timers.py?line=303'>304</a>\u001b[0m     \u001b[39mwith\u001b[39;00m hierarchical_timer(func\u001b[39m.\u001b[39m\u001b[39m__qualname__\u001b[39m):\n\u001b[1;32m--> <a href='file:///c%3A/Users/nathan/AppData/Local/Programs/Python/Python310/lib/site-packages/mlagents_envs/timers.py?line=304'>305</a>\u001b[0m         \u001b[39mreturn\u001b[39;00m func(\u001b[39m*\u001b[39margs, \u001b[39m*\u001b[39m\u001b[39m*\u001b[39mkwargs)\n",
      "File \u001b[1;32mc:\\Users\\nathan\\AppData\\Local\\Programs\\Python\\Python310\\lib\\site-packages\\mlagents_envs\\environment.py:350\u001b[0m, in \u001b[0;36mUnityEnvironment.step\u001b[1;34m(self)\u001b[0m\n\u001b[0;32m    <a href='file:///c%3A/Users/nathan/AppData/Local/Programs/Python/Python310/lib/site-packages/mlagents_envs/environment.py?line=347'>348</a>\u001b[0m     outputs \u001b[39m=\u001b[39m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_communicator\u001b[39m.\u001b[39mexchange(step_input, \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_poll_process)\n\u001b[0;32m    <a href='file:///c%3A/Users/nathan/AppData/Local/Programs/Python/Python310/lib/site-packages/mlagents_envs/environment.py?line=348'>349</a>\u001b[0m \u001b[39mif\u001b[39;00m outputs \u001b[39mis\u001b[39;00m \u001b[39mNone\u001b[39;00m:\n\u001b[1;32m--> <a href='file:///c%3A/Users/nathan/AppData/Local/Programs/Python/Python310/lib/site-packages/mlagents_envs/environment.py?line=349'>350</a>\u001b[0m     \u001b[39mraise\u001b[39;00m UnityCommunicatorStoppedException(\u001b[39m\"\u001b[39m\u001b[39mCommunicator has exited.\u001b[39m\u001b[39m\"\u001b[39m)\n\u001b[0;32m    <a href='file:///c%3A/Users/nathan/AppData/Local/Programs/Python/Python310/lib/site-packages/mlagents_envs/environment.py?line=350'>351</a>\u001b[0m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_update_behavior_specs(outputs)\n\u001b[0;32m    <a href='file:///c%3A/Users/nathan/AppData/Local/Programs/Python/Python310/lib/site-packages/mlagents_envs/environment.py?line=351'>352</a>\u001b[0m rl_output \u001b[39m=\u001b[39m outputs\u001b[39m.\u001b[39mrl_output\n",
      "\u001b[1;31mUnityCommunicatorStoppedException\u001b[0m: Communicator has exited."
     ]
    }
   ],
   "source": [
    "env = wave_gym_env.CustomEnv(env_path, timescale=2)\n",
    "\n",
    "obs = env.reset()\n",
    "dones = False\n",
    "while not dones:\n",
    "    action, _states = model.predict(obs)\n",
    "    obs, rewards, dones, info = env.step(action)\n",
    "\n",
    "env.close()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "env.close()"
   ]
  }
 ],
 "metadata": {
  "interpreter": {
   "hash": "fdac1d424f9df1d866b72a8e35a4caee1c4f78e3bed908179de4c636fdd990d3"
  },
  "kernelspec": {
   "display_name": "Python 3.10.4 64-bit",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.4"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
